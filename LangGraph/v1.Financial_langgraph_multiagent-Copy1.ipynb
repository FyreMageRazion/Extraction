{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377d647-991c-484b-8b3d-70336edaf7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570eb96-1a33-484f-a974-b59d0894e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain langchain_openai langgraph openbb openbb-yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ebf04b6-ec9f-4d59-a25e-7f1c87a095b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, Any, List, Optional\n",
    "from typing import TypedDict, Literal\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent  # agent builder used in ref\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Tavily search (community tool)\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# LangGraph imports (StateGraph-based flow)\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Chat interface used in your reference\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b268913-c6ba-4b2b-9d76-4950d70d1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"FinancialAssistant/1.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9684241-5bcb-429b-a504-c13ec6f58693",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"Financial_Docs\"\n",
    "\n",
    "def load_all_pdfs(path):\n",
    "    docs = []\n",
    "    for pdf_file in glob.glob(f\"{path}/*.pdf\"):\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        pages = loader.load()\n",
    "        for p in pages:\n",
    "            p.metadata[\"source\"] = os.path.basename(pdf_file)\n",
    "        docs.extend(pages)\n",
    "    return docs\n",
    "\n",
    "raw_docs = load_all_pdfs(DATA_DIR)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunked_docs = splitter.split_documents(raw_docs)\n",
    "\n",
    "# Attach chunk indices\n",
    "for idx, doc in enumerate(chunked_docs):\n",
    "    doc.metadata[\"chunk_index\"] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc99b1d9-009c-4c6b-95ad-cbfbdb911b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2025-10-22T16:03:23-04:00', 'title': '0001065280-25-000406', 'author': 'EDGAR® Online LLC, a subsidiary of OTC Markets Group', 'subject': 'Form 10-Q filed on 2025-10-22 for the period ending 2025-09-30', 'keywords': '0001065280-25-000406; ; 10-Q', 'moddate': '2025-10-22T16:03:31-04:00', 'source': 'Netflix.pdf', 'total_pages': 42, 'page': 0, 'page_label': '1', 'chunk_index': 0}, page_content='UNITED STATES\\nSECURITIES AND EXCHANGE COMMISSION\\nWashington, D.C. 20549\\nFORM 10-Q\\n(Mark One)\\n☒  QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the quarterly period ended September 30, 2025\\nOR\\n☐  TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the transition period from                  to                 \\nCommission File Number: 001-35727\\nNetflix, Inc.\\n(Exact name of Registrant as specified in its charter)\\nDelaware 77-0467272\\n(State or other jurisdiction ofincorporation or organization) (I.R.S. EmployerIdentification Number)\\n121 Albright Way, Los Gatos, California 95032\\n(Address of principal executive offices) (Zip Code)\\n(408) 540-3700\\n(Registrant’s telephone number, including area code)'),\n",
       " Document(metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2025-10-22T16:03:23-04:00', 'title': '0001065280-25-000406', 'author': 'EDGAR® Online LLC, a subsidiary of OTC Markets Group', 'subject': 'Form 10-Q filed on 2025-10-22 for the period ending 2025-09-30', 'keywords': '0001065280-25-000406; ; 10-Q', 'moddate': '2025-10-22T16:03:31-04:00', 'source': 'Netflix.pdf', 'total_pages': 42, 'page': 0, 'page_label': '1', 'chunk_index': 1}, page_content='121 Albright Way, Los Gatos, California 95032\\n(Address of principal executive offices) (Zip Code)\\n(408) 540-3700\\n(Registrant’s telephone number, including area code)\\nSecurities registered pursuant to Section 12(b) of the Act:\\nTitle of each class Trading Symbol(s) Name of each exchange on which registered\\nCommon stock, par value $0.001 per share NFLX NASDAQ Global Select Market\\nIndicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the\\npreceding 12 months (or for such shorter period that the registrant was required to file such reports) and (2) has been subject to such filing requirements for the past 90\\ndays.    Yes  ☒     No  ☐')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a41bbc40-7c84-405e-ab04-34249f380ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunked_docs, emb)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 12}  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bce92c02-9733-4613-9a0b-1bfc74bbffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\") # \"BAAI/bge-reranker-v2-m3\" is a bit slow while testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ff2dfb1-93af-4280-b6df-0f0cd6b2a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_crossencoder(query, docs, top_k=5, batch_size=16):\n",
    "    if not docs:\n",
    "        return []\n",
    "    pairs = [[query, d.page_content] for d in docs]\n",
    "    scores = reranker.predict(pairs, batch_size=batch_size) \n",
    "    order = np.argsort(scores)[::-1]\n",
    "    return [docs[i] for i in order[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ba6912b-1baa-485c-b3a7-dd40fa5ae348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs, max_chars=900):\n",
    "    blocks = []\n",
    "    citation_map = {}\n",
    "    for i, d in enumerate(docs, start=1):\n",
    "        txt = d.page_content[:max_chars]\n",
    "        md = d.metadata\n",
    "        blocks.append(f\"[{i}] Source: {md['source']} | chunk={md['chunk_index']} \\n{txt}\")\n",
    "        citation_map[i] = {\n",
    "            \"source\": md[\"source\"],\n",
    "            \"chunk_index\": md[\"chunk_index\"],\n",
    "            \"excerpt\": txt\n",
    "        }\n",
    "    return \"\\n\\n---\\n\\n\".join(blocks), citation_map\n",
    "\n",
    "\n",
    "def generate_answer(question, docs):\n",
    "    context, citation_map = format_docs(docs)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a factual research assistant. \n",
    "Use ONLY the context blocks below to answer. \n",
    "Use inline citations like [1][2]. \n",
    "If unknown, say \"Not answerable from documents.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer with citations, then add a \"SOURCES\" section.\n",
    "\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    output = llm.invoke(prompt).content\n",
    "    return output, citation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34a91f90-dc69-4819-91fd-1ec8658bfcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(question: str) -> str:\n",
    "    initial_docs = retriever.invoke(question)\n",
    "    top_docs = rerank_with_crossencoder(question, initial_docs, top_k=5)\n",
    "        \n",
    "    answer, sources = generate_answer(question, top_docs)\n",
    "    return answer + json.dumps(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f239445f-63f0-4a99-bbd6-887f785b61b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle Cloud Applications (OCA) are positioned as an industry-leading business innovation platform that leverages Oracle Cloud Infrastructure (OCI). The OCA offerings provide a broad suite of modular, next-generation cloud software applications that span all core business functions. This includes solutions like Oracle Fusion Cloud ERP, which aims to improve decision-making and workforce productivity by utilizing a single data and security model with a common user interface [3][4]. \n",
      "\n",
      "The comprehensive and flexible deployment models of OCA are seen as a key factor in Oracle's growth strategy, allowing customers to choose options that best meet their specific business needs. This flexibility is a significant differentiator compared to competitors who may offer fewer options and more restrictive deployment models [2]. \n",
      "\n",
      "Furthermore, Oracle anticipates continued growth in cloud services and license support expenses, driven by customer demand for enhanced data center capacity and the establishment of additional data centers in new geographic locations [4]. This expectation indicates a positive outlook for OCA's performance in the market.\n",
      "\n",
      "SOURCES:\n",
      "[1] oracle.pdf | chunk=267  \n",
      "[2] oracle.pdf | chunk=250  \n",
      "[3] oracle.pdf | chunk=268  \n",
      "[4] oracle.pdf | chunk=238  {\"1\": {\"source\": \"oracle.pdf\", \"chunk_index\": 267, \"excerpt\": \"engineering, consumer packaged goods, defense and intelligence, educa\\u0000on, \\ufb01nancial services, government, healthcare, high technology, hospitality, industrial \\nmanufacturing, life sciences, media and entertainment, oil and gas, professional services, public safety, restaurant, retail, travel and logis\\u0000cs, u\\u0000li\\u0000es and \\nwholesale distribu\\u0000on industries, among others.\\nOracle Cloud Applica\\u0000ons (OCA)\\nThe broad spectrum of OCA o\\ufb00erings provides customers with a choice of so\\u0000ware applica\\u0000ons delivered via a cloud-based IT environment that we deploy and \\nmanage and that customers purchase by entering into a subscrip\\u0000on agreement with us for a stated period. Our OCA o\\ufb00erings represent an industry leading\"}, \"2\": {\"source\": \"oracle.pdf\", \"chunk_index\": 250, \"excerpt\": \"how they deploy Oracle applica\\u0000ons and infrastructure technologies. We believe that o\\ufb00ering customers broad, comprehensive, \\ufb02exible and interoperable \\ndeployment models for Oracle applica\\u0000ons and infrastructure technologies is important to our growth strategy and be\\u0000er addresses customer needs rela\\u0000ve \\nto our compe\\u0000tors, many of whom provide fewer o\\ufb00erings, more restric\\u0000ve deployment models and less \\ufb02exibility for customers transi\\u0000oning to cloud-based \\nIT environments.\\nOracle Cloud Applica\\u0000ons (OCA) and Oracle Cloud Infrastructure (OCI, collec\\u0000vely with OCA, Oracle Cloud Services) o\\ufb00erings provide comprehensive and \\nintegrated applica\\u0000ons and infrastructure services, enabling our customers to choose the best op\\u0000on that meets their speci\\ufb01c business needs. Oracle Cloud\"}, \"3\": {\"source\": \"oracle.pdf\", \"chunk_index\": 268, \"excerpt\": \"manage and that customers purchase by entering into a subscrip\\u0000on agreement with us for a stated period. Our OCA o\\ufb00erings represent an industry leading \\nbusiness innova\\u0000on pla\\u0000orm leveraging OCI and include a broad suite of modular, next-genera\\u0000on cloud so\\u0000ware applica\\u0000ons spanning all core business \\nfunc\\u0000ons, including, among others:\\n\\u2022 Oracle Fusion Cloud ERP, which is designed to be a complete and integrated ERP solu\\u0000on to help organiza\\u0000ons improve decision making and \\nworkforce produc\\u0000vity, and to op\\u0000mize back-o\\ufb03ce opera\\u0000ons by u\\u0000lizing a single data and security model with a common user interface; \\n\\u2022 Oracle Fusion Cloud Enterprise Performance Management (EPM), which is designed to analyze \\ufb01nancial performance, drive accurate and agile\"}, \"4\": {\"source\": \"oracle.pdf\", \"chunk_index\": 238, \"excerpt\": \"\\u2022 our belief that Oracle Fusion Cloud Enterprise Resource Planning is a strategic suite of applica\\u0000ons that is founda\\u0000onal to facilita\\u0000ng and extrac\\u0000ng \\nmore business value out of the adop\\u0000on of other OCA o\\ufb00erings as customers realize the value of a common data model that spans across core \\nbusiness applica\\u0000ons;\\n\\u2022 our belief that our OCA o\\ufb00erings remove business boundaries between front- and back-o\\ufb03ce ac\\u0000vi\\u0000es;\\n\\u2022 our expecta\\u0000on that current and expected customer demand will require con\\u0000nued growth in our cloud services and license support expenses in \\norder to increase our exis\\u0000ng data center capacity and establish addi\\u0000onal data centers in new geographic loca\\u0000ons;\"}, \"5\": {\"source\": \"oracle.pdf\", \"chunk_index\": 272, \"excerpt\": \"Customers access OCA o\\ufb00erings u\\u0000lizing common web browsers via a broad spectrum of devices.\\nCustomers, partners and other interested par\\u0000es may elect to subscribe to Oracle applica\\u0000ons and infrastructure training and cer\\u0000\\ufb01ca\\u0000on programs through \\nlearning subscrip\\u0000ons o\\ufb00ered by Oracle University. Learners generally have unlimited access to course content delivered during the subscrip\\u0000on period.\\nWe believe that the comprehensiveness and breadth of our cloud applica\\u0000ons o\\ufb00erings di\\ufb00eren\\u0000ate us from many of our compe\\u0000tors that o\\ufb00er more limited \\nor specialized applica\\u0000ons. Our cloud applica\\u0000ons o\\ufb00erings are designed to support connected business processes in the cloud and are centered on an\"}}\n"
     ]
    }
   ],
   "source": [
    "question = \"How is Oracle Cloud Applications (OCA)  performing?\"\n",
    "answer = answer_query(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cfbe9da4-b9b7-459f-b971-4af2ed6023c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rag_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Has details of latest quartely and annual performance of Netflix and Oracle.\n",
    "    RAG retrieval tool. Expects a FAISS vectorstore saved at ./faiss_store or built at runtime.\n",
    "    Returns top-k documents joined as a text blob.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        answer = answer_query(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error in rag_search: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b3c85c15-91d2-4155-ba02-916060f41c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router keywords\n",
    "WEB_KEYWORDS = [r\"\\blatest\\b\", r\"\\btoday\\b\", r\"\\bcurrent\\b\", r\"\\brecent\\b\", r\"\\bbreaking\\b\"]\n",
    "RAG_KEYWORDS = [r\"\\bpolicy\\b\", r\"\\binternal\\b\", r\"\\bproduct\\b\", r\"\\bmanual\\b\", r\"\\bknowledge base\\b\"]\n",
    "\n",
    "# LLM factory (ChatOpenAI wrapper used in your snippet)\n",
    "def get_chat_llm(model: str = \"gpt-4o-mini\", temperature: float = 0.0) -> ChatOpenAI:\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY must be set in environment\")\n",
    "    return ChatOpenAI(model=model, temperature=temperature, api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Lightweight HTML text extractor\n",
    "def extract_text(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # remove script/style\n",
    "    for s in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        s.decompose()\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    lines = [line.strip() for line in text.splitlines()]\n",
    "    text = \"\\n\".join([l for l in lines if l])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "25912f34-81ad-40ed-913f-0fb64ab73e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def finance_web_search(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Use TavilySearchResults to find articles and investment blogs for a given\n",
    "    `topic` (e.g., 'NVIDIA Q3 earnings analysis', 'impact of Fed rate hike on tech stocks').\n",
    "    It fetches the top pages and summarizes them with a Financial Analyst LLM.\n",
    "    Returns a plain text aggregation of financial summaries.\n",
    "    \"\"\"\n",
    "    if TAVILY_API_KEY == \"YOUR_TAVILY_API_KEY\" or not TAVILY_API_KEY:\n",
    "        return \"TAVILY_API_KEY not set; cannot run Tavily search. Please set the environment variable.\"\n",
    "\n",
    "    # Build search query: Directly use the topic, adding context for better results\n",
    "    query = f\"financial analysis and investment insights on {topic}\"\n",
    "\n",
    "    # Use the Tavily tool wrapper\n",
    "    search = TavilySearchResults(k=5, api_key=TAVILY_API_KEY)\n",
    "    results = search.run(query)\n",
    "    urls = [r.get(\"url\") for r in results if \"url\" in r]\n",
    "\n",
    "    llm = get_chat_llm(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    summaries: List[str] = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            text = extract_text(resp.text)\n",
    "            # trim to reasonable length for LLM\n",
    "            text = text[:12000]\n",
    "\n",
    "            prompt = [\n",
    "                SystemMessage(content=\"You are a sophisticated Financial Analyst and content summarizer. Produce a crisp summary focused on investment takeaways, risks, and financial implications.\"),\n",
    "                HumanMessage(content=f\"Summarize the following webpage content for financial and investment insights related to '{topic}':\\n\\n{text}\")\n",
    "            ]\n",
    "            \n",
    "            response = llm.invoke(prompt)\n",
    "            # The ChatOpenAI response object typically has a 'content' attribute\n",
    "            summary = getattr(response, \"content\", str(response))\n",
    "            summaries.append(f\"Source URL: {url}\\nSummary: {summary}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            summaries.append(f\"Source URL: {url}\\nError summarizing page: {e}\\n\")\n",
    "\n",
    "    return \"\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "89fef3bf-4906-4b44-a254-31fccfd5818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Router node: performs a quick heuristic check, then falls back to LLM.\n",
    "    Output: {\"route\": \"web_search\" | \"rag\" | \"llm\"}\n",
    "    \"\"\"\n",
    "    llm = get_chat_llm(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Classify the user query into one routing category. \"\n",
    "                \"Reply with exactly ONE of: web_search, rag, llm. \"\n",
    "                \"No explanation.\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        resp = llm.invoke(prompt)\n",
    "        output = getattr(resp, \"content\", \"\").strip().lower()\n",
    "\n",
    "        # sanitize LLM output\n",
    "        if \"web_search\" in output:\n",
    "            return {\"route\": \"web_search\"}\n",
    "        if \"rag\" in output:\n",
    "            return {\"route\": \"rag\"}\n",
    "        if \"llm\" in output:\n",
    "            return {\"route\": \"llm\"}\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return {\"route\": \"llm\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "82c5aea9-599a-4ac4-9432-aa7f0dc3858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_summarizer_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Synthesize the final financial analysis report from evidence present in the state.\n",
    "    Expects state to have:\n",
    "      - topic (the stock ticker(s) or financial question)\n",
    "      - route (data source, e.g., 'OpenBB', 'WebSearch')\n",
    "      - evidence (string or list of source data/summaries)\n",
    "    \n",
    "    Returns {\"final_report\": \"<text>\"}\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    # Updated variables for financial context\n",
    "    topic = state.get(\"topic\", \"the requested financial subject\")\n",
    "    route = state.get(\"route\", \"LLM reasoning\")\n",
    "    evidence = state.get(\"evidence\", \"\")\n",
    "    \n",
    "\n",
    "    # normalize evidence into single text blob\n",
    "    if isinstance(evidence, list):\n",
    "        ev_text = \"\\n\\n\".join(evidence)\n",
    "    else:\n",
    "        ev_text = str(evidence)\n",
    "\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a Chief Investment Strategist and expert financial report writer. Your analysis must be detailed, objective, and actionable. Produce executive-level investment summaries.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": f\"\"\"\n",
    "Write a comprehensive **Financial Analysis and Investment Report** for the topic: **{topic}**. \n",
    "Base your analysis ONLY on the raw data and insights provided in the EVIDENCE section below.\n",
    "\n",
    "If the topic involves a comparison (e.g., NVIDIA vs. INTEL), dedicate a section to the comparative analysis.\n",
    "If the evidence includes a clear conclusion (like a \"better choice\"), explicitly state the rationale.\n",
    "\n",
    "--- EVIDENCE (from {route}) ---\n",
    "{ev_text}\n",
    "\n",
    "Output format:\n",
    "**Executive Summary and Investment Thesis**\n",
    "- (Start with a 1-2 sentence recommendation or high-level conclusion.)\n",
    "\n",
    "**Key Financial Metrics Analysis**\n",
    "- (Analyze P/E ratio, market cap, growth rates, or other fundamental data from the evidence.)\n",
    "\n",
    "**Comparative Analysis (If Applicable)**\n",
    "- (If multiple stocks are involved, compare them directly based on the metrics you analyzed.)\n",
    "\n",
    "**Recent Market Insights and News**\n",
    "- (Summarize any external data/news collected.)\n",
    "\n",
    "**Risk Factors and Opportunities**\n",
    "- (Based on the evidence, list the main risks and potential growth opportunities.)\n",
    "\n",
    "**Final Investment Outlook**\n",
    "- (Provide a clear, detailed final recommendation on the action to take (e.g., Buy, Hold, Sell) or the final answer to the user's specific question.)\n",
    "\"\"\"}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    final = getattr(response, \"content\", str(response))\n",
    "    return {\"final_report\": final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "632b108b-aea6-4e31-944a-a9cfda238029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union, Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "from operator import itemgetter # Required for LangGraph state management\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Define the Reducer Function (Crucial for conversation memory)\n",
    "def add_messages(left: list, right: list):\n",
    "    \"\"\"Reducer function to correctly append new messages to the list.\"\"\"\n",
    "    # This function is how LangGraph merges new messages into the state's message list\n",
    "    return left + right\n",
    "\n",
    "# Define the State\n",
    "class FinancialAgentState(TypedDict, total=False):\n",
    "    \"\"\"\n",
    "    Represents the state of our financial assistant conversation.\n",
    "    It combines the conversational history with explicit data fields \n",
    "    for multi-step financial analysis.\n",
    "    \"\"\"\n",
    "    # --- CORE LANGGRAPH FIELDS ---\n",
    "    messages: Annotated[List[Union[HumanMessage, AIMessage]], add_messages]\n",
    "    \n",
    "    # --- FINANCIAL WORKFLOW FIELDS (Replaces city, weather, tourist) ---\n",
    "    query: str          # The original user query\n",
    "    topic: str          # Replaces 'city'. The main subject (e.g., 'NVIDIA vs INTEL')\n",
    "    \n",
    "    # Stores all data retrieved from tools (OpenBB, WebSearch). Replaces 'evidence'.\n",
    "    raw_data: str \n",
    "    \n",
    "    # The final, synthesized human-readable output (Replaces 'final_report')\n",
    "    final_report: str\n",
    "    \n",
    "    # A control variable to manage flow between nodes (e.g., in a router)\n",
    "    route: Literal[\"web_search\", \"rag\", \"llm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "015c0f91-9c5f-43ff-a86a-441842a16540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(model=\"gpt-4o-mini\", temperature=0):\n",
    "    return ChatOpenAI(model=model, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7c4da3ea-8134-40e6-8a74-5111031896a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_llm():\n",
    "    \"\"\"\n",
    "    Returns an LLM used only for routing/classification.\n",
    "    No tools. Pure prompt → output.\n",
    "    \"\"\"\n",
    "    return get_llm(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "bc4abd72-76f2-4c0b-ac51-8e133a2454f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_financial_agent():\n",
    "    model = get_llm(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a helpful financial reasoning assistant. \"\n",
    "        \"Analyze the user's query and provide structured reasoning. \"\n",
    "        \"Only perform reasoning here — do not search the web or retrieve external data. \"\n",
    "        \"If reasoning seems insufficient for the user's question, the router will decide another path.\"\n",
    "    )\n",
    "\n",
    "    return create_agent(\n",
    "        model=model,\n",
    "        tools=[],               # no tools\n",
    "        system_prompt=system_prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9e597f3a-d14e-4b22-a36f-6e5d0dcac701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_query_node(state: FinancialAgentState) -> FinancialAgentState:\n",
    "    \"\"\"\n",
    "    Entry point for the financial assistant.\n",
    "    Cleans, clarifies, and normalizes the user query to improve routing accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract last HumanMessage from messages\n",
    "    messages = state.get(\"messages\", [])\n",
    "    user_query = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if msg.type == \"human\":\n",
    "            user_query = msg.content\n",
    "            break\n",
    "\n",
    "    if not user_query:\n",
    "        return {\"query\": \"\", \"topic\": \"\"}\n",
    "\n",
    "    # IMPORTANT: Use a RAW LLM, not the financial agent\n",
    "    llm = get_llm(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # 1. Refine the query\n",
    "    refine_system = (\n",
    "        \"You are a financial reasoning assistant.\\n\"\n",
    "        \"Refine the user's query so downstream components can understand it.\\n\"\n",
    "        \"Return ONLY the improved query.\\n\"\n",
    "        \"Do NOT answer the question.\\n\"\n",
    "    )\n",
    "\n",
    "    resp = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": refine_system},\n",
    "        {\"role\": \"user\", \"content\": f\"Refine this financial query: {user_query}\"}\n",
    "    ])\n",
    "\n",
    "    refined = resp.content.strip()\n",
    "\n",
    "    # 2. Extract topic\n",
    "    topic_system = (\n",
    "        \"Extract the main financial topic from the query in 3–6 words.\\n\"\n",
    "        \"Return ONLY the topic phrase.\"\n",
    "    )\n",
    "\n",
    "    topic_resp = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": topic_system},\n",
    "        {\"role\": \"user\", \"content\": refined}\n",
    "    ])\n",
    "\n",
    "    topic = topic_resp.content.strip()\n",
    "\n",
    "    # MUST return a dict\n",
    "    return {\n",
    "        \"query\": refined,\n",
    "        \"topic\": topic\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1dc5b336-ed32-4047-922a-b82ddd3569d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. ROUTER NODE\n",
    "# ------------------------------------------------------------\n",
    "def router_node(state: FinancialAgentState) -> FinancialAgentState:\n",
    "    \"\"\"\n",
    "    Classifies query into: web_search, rag, llm.\n",
    "    \"\"\"\n",
    "\n",
    "    query = state.get(\"query\", \"\").strip()\n",
    "\n",
    "    if not query:\n",
    "        return {\"route\": \"llm\"}\n",
    "\n",
    "    llm = build_classifier_llm()\n",
    "\n",
    "    resp = llm.invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Classify the user's financial query into EXACTLY one category:\\n\"\n",
    "                \"- web_search : if the question needs very recent or external market/news data.\\n\"\n",
    "                \"- rag        : if the question should use internal knowledgebase or company reports.\\n\"\n",
    "                \"- llm        : if the question is reasoning-oriented and needs no external data.\\n\\n\"\n",
    "                \"Return ONLY one token: web_search, rag, or llm.\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ])\n",
    "\n",
    "    route = resp.content.strip().lower()\n",
    "\n",
    "    allowed = {\"web_search\", \"rag\", \"llm\"}\n",
    "    if route not in allowed:\n",
    "        route = \"llm\"\n",
    "\n",
    "    return {\"route\": route}\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. WEB SEARCH NODE (Tavily)\n",
    "# ------------------------------------------------------------\n",
    "def web_search_node(state: FinancialAgentState) -> FinancialAgentState:\n",
    "    q = state.get(\"query\") or state.get(\"city\") or \"\"\n",
    "    # Replace with TavilySearchResults run\n",
    "    evidence = f\"(Mock Tavily search results for: {q})\"\n",
    "    return {\"evidence\": evidence}\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. RAG NODE (FAISS / docstore)\n",
    "# ------------------------------------------------------------\n",
    "def rag_node(state: FinancialAgentState) -> FinancialAgentState:\n",
    "    q = state.get(\"query\", \"\")\n",
    "    # Replace with real RAG chain\n",
    "    evidence = f\"(Mock RAG retrieval for: {q})\"\n",
    "    return {\"evidence\": evidence}\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. LLM REASONING NODE\n",
    "# ------------------------------------------------------------\n",
    "def llm_node(state: FinancialAgentState) -> FinancialAgentState:\n",
    "    q = state.get(\"query\", \"\")\n",
    "    llm = get_llm()\n",
    "\n",
    "    resp = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": \"Answer concisely.\"},\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "    ])\n",
    "\n",
    "    return {\"evidence\": resp.content}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. FINAL FINANCIAL SUMMARIZER NODE\n",
    "# ------------------------------------------------------------\n",
    "def financial_summarizer_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Synthesize the final financial analysis report from evidence present in the state.\n",
    "    \n",
    "    Expects state to have:\n",
    "      - topic (the stock ticker(s) or financial question)\n",
    "      - raw_data (string containing all source data/summaries collected by tools)\n",
    "    \n",
    "    Returns {\"final_report\": \"<text>\"}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use a strong model for final synthesis\n",
    "    llm = get_llm(model=\"gpt-4o\") \n",
    "    \n",
    "    # Use the new financial state keys: topic and raw_data\n",
    "    topic = state.get(\"topic\", state.get(\"query\", \"the requested financial subject\"))\n",
    "    raw_data = state.get(\"raw_data\", \"No data was retrieved by the tools.\")\n",
    "\n",
    "    # Define the system prompt for the Financial Analyst persona\n",
    "    system_instruction = (\n",
    "        \"You are a Chief Investment Strategist and expert financial report writer. \"\n",
    "        \"Your analysis must be detailed, objective, and actionable. Produce executive-level investment summaries. \"\n",
    "        \"DO NOT repeat the raw data, only synthesize the insights into a coherent report.\"\n",
    "    )\n",
    "    \n",
    "    user_instruction = f\"\"\"\n",
    "Write a comprehensive **Financial Analysis and Investment Report** for the topic: **{topic}**. \n",
    "Base your analysis ONLY on the raw data and insights provided in the EVIDENCE section below.\n",
    "\n",
    "If the topic involves a comparison (e.g., NVIDIA vs. INTEL), dedicate a section to the comparative analysis.\n",
    "If the evidence includes a clear conclusion, explicitly state the rationale.\n",
    "\n",
    "--- EVIDENCE (Raw Tool Data) ---\n",
    "{raw_data}\n",
    "\n",
    "Output format:\n",
    "**Executive Summary and Investment Thesis**\n",
    "- (Start with a 1-2 sentence recommendation or high-level conclusion.)\n",
    "\n",
    "**Key Financial Metrics Analysis**\n",
    "- (Analyze P/E ratio, market cap, growth rates, or other fundamental data from the evidence.)\n",
    "\n",
    "**Comparative Analysis (If Applicable)**\n",
    "- (If multiple stocks are involved, compare them directly based on the metrics you analyzed.)\n",
    "\n",
    "**Recent Market Insights and News**\n",
    "- (Summarize any external data/news collected.)\n",
    "\n",
    "**Final Investment Outlook**\n",
    "- (Provide a clear, detailed final recommendation on the action to take (e.g., Buy, Hold, Sell) or the final answer to the user's specific question.)\n",
    "\"\"\"\n",
    "\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": system_instruction},\n",
    "        {\"role\": \"user\", \"content\": user_instruction}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"final_report\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b3e44b06-8621-4447-b69d-3997fb856b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flow():\n",
    "    \"\"\"Creates the LangGraph flow for the financial analysis assistant.\"\"\"\n",
    "    graph = StateGraph(FinancialAgentState)\n",
    "\n",
    "    # 1. Add Nodes\n",
    "    graph.add_node(\"refine_query\", refine_query_node)\n",
    "    graph.set_entry_point(\"refine_query\")\n",
    "    \n",
    "\n",
    "\n",
    "    graph.add_node(\"router\", router_node)\n",
    "    \n",
    "    graph.add_node(\"web_search\", web_search_node)\n",
    "    graph.add_node(\"rag\", rag_node)\n",
    "    graph.add_node(\"llm_reason\", llm_node)\n",
    "    \n",
    "    graph.add_node(\"summarizer\", financial_summarizer_node)\n",
    "\n",
    "\n",
    "    graph.add_edge(\"refine_query\", \"router\")\n",
    "    \n",
    "    graph.add_conditional_edges(\n",
    "        \"router\",\n",
    "        lambda s: s[\"route\"],\n",
    "        {\n",
    "            \"web_search\": \"web_search\",\n",
    "            \"rag\": \"rag\",\n",
    "            \"llm\": \"llm_reason\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 5. Final Step\n",
    "    graph.add_edge(\"web_search\", \"summarizer\")\n",
    "    graph.add_edge(\"rag\", \"summarizer\")\n",
    "    graph.add_edge(\"llm_reason\", \"summarizer\")\n",
    "\n",
    "    graph.add_edge(\"summarizer\", END)\n",
    "\n",
    "    return graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b7aca775-4e53-4536-839f-7ddf49cd8421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINANCIAL REPORT =====\n",
      "\n",
      "**Executive Summary and Investment Thesis**\n",
      "- Based on the valuation metrics and recent market performance, NVIDIA presents a compelling growth opportunity, albeit with a higher risk profile due to its premium valuation. Oracle, on the other hand, offers a more stable investment with moderate growth prospects and a more attractive valuation. Investors should consider NVIDIA for aggressive growth exposure and Oracle for stability and income.\n",
      "\n",
      "**Key Financial Metrics Analysis**\n",
      "- **NVIDIA**: The company exhibits a high Price-to-Earnings (P/E) ratio, reflecting strong investor confidence in its future growth potential, driven by its leadership in AI and graphics processing units (GPUs). NVIDIA's market capitalization has surged, indicating robust market sentiment and expectations of continued revenue growth. However, the elevated P/E ratio suggests that the stock is priced for perfection, and any deviation from growth expectations could lead to significant volatility.\n",
      "\n",
      "- **Oracle**: Oracle's P/E ratio is considerably lower than NVIDIA's, suggesting a more conservative valuation. This aligns with Oracle's business model, which focuses on enterprise software and cloud services, offering steady, albeit slower, growth. Oracle's market cap reflects its established position in the tech industry, with consistent revenue streams and a strong focus on cloud infrastructure expansion.\n",
      "\n",
      "**Comparative Analysis**\n",
      "- **Growth vs. Stability**: NVIDIA's high P/E ratio and market cap growth highlight its position as a high-growth stock, driven by innovation and expansion in AI and gaming sectors. In contrast, Oracle's lower P/E ratio and stable market cap suggest a value-oriented investment with less volatility and a focus on long-term, steady growth.\n",
      "- **Risk and Reward**: Investors seeking high returns and willing to accept higher risk may find NVIDIA attractive. Conversely, those prioritizing capital preservation and income might prefer Oracle, given its lower valuation and stable growth trajectory.\n",
      "\n",
      "**Recent Market Insights and News**\n",
      "- NVIDIA has been at the forefront of AI advancements, which has significantly boosted its stock performance. The company's strategic partnerships and product innovations continue to drive investor optimism.\n",
      "- Oracle has been expanding its cloud services, which has been well-received in the market. Recent earnings reports indicate solid performance in its cloud segment, contributing to a positive outlook for future growth.\n",
      "\n",
      "**Final Investment Outlook**\n",
      "- **NVIDIA**: Given its high growth potential and market leadership in AI, a \"Buy\" recommendation is suitable for investors with a high-risk tolerance and a long-term investment horizon. However, they should be prepared for potential volatility due to its premium valuation.\n",
      "- **Oracle**: A \"Hold\" recommendation is appropriate for investors seeking stability and income. Oracle's consistent performance and strategic focus on cloud services provide a solid foundation for moderate growth, making it a reliable component of a diversified portfolio.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Note: This is a simplified execution. A real setup requires the agent runnable\n",
    "    # and tool definitions to be correctly scoped and initialized.\n",
    "    flow = create_flow()\n",
    "\n",
    "    input_state = {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Compare the valuation and recent news for NVIDIA and Oracle.\")\n",
    "        ],\n",
    "        \"query\": \"Compare the valuation and recent news for NVIDIA and Oracle.\",\n",
    "        \"topic\": \"NVIDIA vs Oracle Stocks\",\n",
    "        \"raw_data\": \"\",\n",
    "    }\n",
    "\n",
    "    result = flow.invoke(input_state)\n",
    "\n",
    "    print(\"\\n===== FINANCIAL REPORT =====\\n\")\n",
    "    print(result.get(\"final_report\") or result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b16a3-21c3-483d-a48b-730a5df4f0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20850942-0cff-4700-a783-8310f821fb24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956ea60-e672-4c2b-a78b-c36d23550742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
