{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05187286-cfcd-4664-a50d-95e665ab11c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npip install -U pip setuptools wheel\\npip install -U torch transformers datasets bitsandbytes accelerate peft[torch] evaluate sentencepiece wandb\\npip install huggingface_hub[hf_xet]\\npip install hf_transfer\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pip install -U pip setuptools wheel\n",
    "pip install -U torch transformers datasets bitsandbytes accelerate peft[torch] evaluate sentencepiece\n",
    "pip install huggingface_hub[hf_xet]\n",
    "pip install hf_transfer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b44d462-3bb5-493c-9053-725a22913211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# BERT QLoRA + LoRA fine-tuning on IMDB sentiment dataset (dipanjanS/imdb_sentiment_finetune_dataset20k)\n",
    "# Ready-to-run notebook-style script. Run cells sequentially in Jupyter / VSCode interactive.\n",
    "\n",
    "\n",
    "# %%\n",
    "# 1) Install required packages (uncomment if running in a fresh environment)\n",
    "# Note: If you already have these installed, you can skip this cell.\n",
    "\n",
    "\n",
    "# !pip install -q transformers==4.35.0 datasets bitsandbytes accelerate peft[torch] wandb evaluate sentencepiece\n",
    "\n",
    "\n",
    "# %%\n",
    "# 2) Imports and basic checks\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "AutoTokenizer,\n",
    "AutoModelForSequenceClassification,\n",
    "TrainingArguments,\n",
    "Trainer,\n",
    "DataCollatorWithPadding,\n",
    "BitsAndBytesConfig,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, get_peft_model_state_dict\n",
    "import evaluate\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22880af0-611c-4753-a37b-1cd06df6d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "print('Torch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device count:', torch.cuda.device_count())\n",
    "    print('Current device:', torch.cuda.current_device())\n",
    "    print('Device name:', torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c576d0c2-102d-46e6-8c9f-231582642362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['review', 'sentiment'],\n",
      "        num_rows: 8000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['review', 'sentiment'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['review', 'sentiment'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3) Configs (edit these if you want)\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "DATASET = \"dipanjanS/imdb_sentiment_finetune_dataset20k\"\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 2e-4\n",
    "OUTPUT_DIR = \"./bert_qlora_imdb_output\"\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# %%\n",
    "# 4) Load dataset\n",
    "raw_ds = load_dataset(DATASET)\n",
    "print(raw_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c28491-737c-45b3-a9fb-2b449642ecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 20000\n"
     ]
    }
   ],
   "source": [
    "# The dataset should have a train split; if not, adapt accordingly.\n",
    "# We'll combine and then split to have a clean train/test split (80/20)\n",
    "if 'train' in raw_ds and len(raw_ds) == 1:\n",
    "    ds = raw_ds['train']\n",
    "else:\n",
    "    # if dataset already has train/test, we'll concatenate whatever splits exist\n",
    "    from datasets import concatenate_datasets\n",
    "    allsplits = [raw_ds[s] for s in raw_ds]\n",
    "    ds = concatenate_datasets(allsplits)\n",
    "\n",
    "\n",
    "print('Total examples:', len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bcc660-9247-4a10-a3eb-26386f96cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 16000 Test size: 4000\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 5) Train/test split\n",
    "split = ds.train_test_split(test_size=0.2, seed=SEED)\n",
    "train_ds = split['train']\n",
    "test_ds = split['test']\n",
    "print('Train size:', len(train_ds), 'Test size:', len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76309cea-1343-4ca1-926b-d0eed9961b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9967fbfef59459792d199b7fb19c198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(1), 'input_ids': tensor([  101,  2157,  1996,  2902,  3496,  2007,  9079,  1998, 10881,  2001,\n",
      "         2589,  8235,  2135,  2009,  4627,  2125,  2007, 11939,  2006,  1037,\n",
      "        25061,  2559,  2200,  6649,  5229,  1010,  1996,  9986,  2015,  2679,\n",
      "         2014,  2046,  1037, 24501,  2271, 26243,  3370,  2282,  1004,  2027,\n",
      "         2693,  2014,  2013,  1996, 25061,  3031,  1037,  2793,  1998, 10975,\n",
      "         5657,  4324,  2014,  2192,  2013,  2008,  2391,  2006,  2009,  2003,\n",
      "         5793,  2008, 11939,  2003,  2383,  1037,  2843,  1997,  4390,  5505,\n",
      "         1998,  2014,  8948,  2024,  7989,  1010,  2004,  2016,  4332,  2000,\n",
      "        11693,  1997, 10975,  5657,  2000,  2025,  2681,  2014,  2217,  2016,\n",
      "        16680,  1000,  2123,  1005,  1056,  2175,  1045,  2293,  2017,  1998,\n",
      "         2059,  2014,  8187,  9010,  1998,  2016,  3632,  2046, 15050,  6545,\n",
      "         1004,  1996,  8080,  3065,  1037,  3154,  4257,  2240,  1004,  1996,\n",
      "        11500,  2175,  2046,  2440,  2041, 12603,  5549,  1004,  3288,  1999,\n",
      "         1037, 13366, 12322, 24714,  8844, 10975,  5657,  4084,  2067,  2013,\n",
      "         1996,  2793,  1999,  5469,  2004,  1996,  7435,  9652,  3046,  2000,\n",
      "         5213,  2014,  5996,  5208,  2540,  2021,  2045,  2003,  2053,  3433,\n",
      "         1998,  2016,  2003, 13800,  3973,  8793,  2757,  2092,  2307,  3496,\n",
      "         2092,  2589,  3057,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 6) Tokenizer and preprocessing\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "\n",
    "# ensure tokenizer has a padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "    examples['review'],\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "\n",
    "train_tok = train_ds.map(preprocess_function, batched=True, remove_columns=[c for c in train_ds.column_names if c != 'sentiment' and c != 'review'])\n",
    "test_tok = test_ds.map(preprocess_function, batched=True, remove_columns=[c for c in test_ds.column_names if c != 'sentiment' and c != 'review'])\n",
    "\n",
    "\n",
    "# Rename label column\n",
    "train_tok = train_tok.rename_column('sentiment', 'labels')\n",
    "test_tok = test_tok.rename_column('sentiment', 'labels')\n",
    "\n",
    "\n",
    "# Set format to PyTorch\n",
    "train_tok.set_format(type='torch', columns=[c for c in train_tok.column_names if c != 'review'])\n",
    "test_tok.set_format(type='torch', columns=[c for c in test_tok.column_names if c != 'review'])\n",
    "\n",
    "\n",
    "print(train_tok[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4387f769-3f57-4ff9-b366-8534b68a8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 7) Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# %%\n",
    "# 8) Prepare quantization config (BitsAndBytes) for 4-bit QLoRA\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8b3d6b-13a6-43d9-a43c-8db272834140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model in 4-bit mode (this may take a while)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# 9) Load the model in 4-bit mode and prepare for k-bit training\n",
    "print('\\nLoading model in 4-bit mode (this may take a while)...')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Important: for some older HF versions use load_in_4bit=True directly (kept as quantization_config for clarity)\n",
    "\n",
    "\n",
    "# resize token embeddings if tokenizer changed\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca992871-1d30-46bd-926e-5c8e08780529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 10) Prepare model for k-bit training (patching some layers for stability)\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "# %%\n",
    "# 11) LoRA config & applying PEFT\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"key\", \"value\"], # BERT attention modules\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64a90e0a-bd28-491a-983c-b090c125024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb2914d-68de-4ca1-90a4-d6cc5b336272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 67607812\n",
      "Trainable params (after LoRA): 886274\n",
      "Trainable fraction: 0.013109\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 12) Utility to count parameters\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "print('Total params:', total_params)\n",
    "print('Trainable params (after LoRA):', trainable_params)\n",
    "print('Trainable fraction: {:.6f}'.format(trainable_params/total_params))\n",
    "\n",
    "\n",
    "# Save the numbers to disk for reporting later\n",
    "with open(os.path.join(OUTPUT_DIR, 'param_counts.txt'), 'w') as f:\n",
    "    f.write(f\"total={total_params}\\ntrainable={trainable_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5816a4b8-16f5-48d8-a367-6faa4ace6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ced0cf971364e5a837690fbc84033a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d703be6d614be9bd1bfd748cba03c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d312b136d84307b6f3d09c3451bc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# 13) Metrics and compute_metrics function\n",
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = accuracy.compute(predictions=preds, references=labels)\n",
    "    p = precision.compute(predictions=preds, references=labels, average='binary')\n",
    "    r = recall.compute(predictions=preds, references=labels, average='binary')\n",
    "    f_1 = f1.compute(predictions=preds, references=labels, average='binary')\n",
    "    return {'accuracy': acc['accuracy'], 'precision': p['precision'], 'recall': r['recall'], 'f1': f_1['f1']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d841f535-ac4e-44f9-8573-410aa0148670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1214/2676419255.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=50,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    report_to=[\"none\"],\n",
    "    gradient_accumulation_steps=1,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model='accuracy'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c43673b-dcfb-4da3-9756-42de4c92ed9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated before training (bytes): 144471552\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 15) (Optional) Initialize Weights & Biases if you want to log there; otherwise HF Trainer will still log locally\n",
    "# import wandb\n",
    "# wandb.init(project='bert-qlora-imdb', name='bert-qlora-run')\n",
    "\n",
    "\n",
    "# %%\n",
    "# 16) Report baseline GPU memory BEFORE training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    before_mem = torch.cuda.memory_allocated()\n",
    "    print('GPU memory allocated before training (bytes):', before_mem)\n",
    "else:\n",
    "    print('No CUDA device; memory measurements will be skipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2cebb8f-89bd-4fea-bb8d-e2403e9a1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d49cb6dc-e1a5-4b4f-9a2d-27682e70eff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 04:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.213600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.172400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.177300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.155200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.160300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (s): 278.9815013408661\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 17) Train\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "end = time.time()\n",
    "print('Training time (s):', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afae67d3-8778-43d8-a2a0-4a9e6d0cde24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated after training (bytes): 175854080\n",
      "Delta (bytes): 31382528\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 18) GPU memory AFTER training\n",
    "if torch.cuda.is_available():\n",
    "    after_mem = torch.cuda.memory_allocated()\n",
    "    print('GPU memory allocated after training (bytes):', after_mem)\n",
    "    print('Delta (bytes):', after_mem - before_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caacb081-09d2-4a56-a33b-76e65a2d01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 19) Save PEFT/LoRA adapters and model\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR, 'qlora_lora_model'))\n",
    "# Save the PEFT adapter separately\n",
    "model.save_pretrained(os.path.join(OUTPUT_DIR, 'qlora_lora_adapter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c60c1dc-58a8-4097-ae00-b27a2dfee385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'eval_loss': 0.3117099702358246, 'eval_accuracy': 0.909, 'eval_precision': 0.8947368421052632, 'eval_recall': 0.9238191975622143, 'eval_f1': 0.9090454772613693, 'eval_runtime': 9.5187, 'eval_samples_per_second': 420.224, 'eval_steps_per_second': 26.264, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 20) Evaluate on the test set\n",
    "metrics = trainer.evaluate(eval_dataset=test_tok)\n",
    "print('Eval metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a332f88e-5a6c-4dd2-88d1-edc4e784f407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current total params: 67607812\n",
      "Current trainable params (LoRA adapters): 886274\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 21) Demonstrate trainable parameter counts before and after applying LoRA\n",
    "# NOTE: If you want to see the model parameter counts BEFORE adding LoRA, you would need to load the same model\n",
    "# without applying get_peft_model. For convenience we show how to do it (commented) and show counts for current model.\n",
    "\n",
    "\n",
    "# Uncomment to compute counts for a non-PEFT baseline (may be heavy if loaded in full precision):\n",
    "# baseline_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "# baseline_total, baseline_trainable = sum(p.numel() for p in baseline_model.parameters()), sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n",
    "# print('Baseline total params:', baseline_total, 'Baseline trainable:', baseline_trainable)\n",
    "\n",
    "\n",
    "print('Current total params:', total_params)\n",
    "print('Current trainable params (LoRA adapters):', trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab44970-61bd-4b9f-bedf-a1099a8863e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 22) Memory efficiency comparison between full fine-tuning and QLoRA\n",
    "# Provide guidance and a small programmatic check when possible. If you can load full model in the environment, uncomment.\n",
    "\n",
    "\n",
    "# NOTE: Full fine-tuning would require loading the full model in fp16 or fp32 and then fine-tuning which might not be possible on small GPUs.\n",
    "# The recommended approach: run the baseline on a machine with enough memory or use the HF Hub to retrieve known model sizes.\n",
    "\n",
    "\n",
    "# Example code to (optionally) measure full model memory usage (commented):\n",
    "# if torch.cuda.is_available():\n",
    "# torch.cuda.empty_cache()\n",
    "# t0 = torch.cuda.memory_allocated()\n",
    "# full = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to('cuda')\n",
    "# t1 = torch.cuda.memory_allocated()\n",
    "# print('Full model memory delta (bytes):', t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff90d1c-f7ae-4fa1-a727-1da7da975cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 16,\n",
      " 'dataset': 'dipanjanS/imdb_sentiment_finetune_dataset20k',\n",
      " 'epochs': 2,\n",
      " 'eval_metrics': {'epoch': 2.0,\n",
      "                  'eval_accuracy': 0.909,\n",
      "                  'eval_f1': 0.9090454772613693,\n",
      "                  'eval_loss': 0.3117099702358246,\n",
      "                  'eval_precision': 0.8947368421052632,\n",
      "                  'eval_recall': 0.9238191975622143,\n",
      "                  'eval_runtime': 9.5187,\n",
      "                  'eval_samples_per_second': 420.224,\n",
      "                  'eval_steps_per_second': 26.264},\n",
      " 'learning_rate': 0.0002,\n",
      " 'max_length': 256,\n",
      " 'model_name': 'bert-base-uncased',\n",
      " 'total_params': 67607812,\n",
      " 'trainable_params': 886274}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 23) Summary report generation (basic)\n",
    "summary = {\n",
    "'model_name': MODEL_NAME,\n",
    "'dataset': DATASET,\n",
    "'max_length': MAX_LENGTH,\n",
    "'batch_size': BATCH_SIZE,\n",
    "'epochs': EPOCHS,\n",
    "'learning_rate': LEARNING_RATE,\n",
    "'total_params': total_params,\n",
    "'trainable_params': trainable_params,\n",
    "'eval_metrics': metrics,\n",
    "}\n",
    "\n",
    "\n",
    "pprint(summary)\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'summary.txt'), 'w') as f:\n",
    "    f.write(str(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beca9f9-13ad-486b-857d-88817408b97a",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943889e-412a-4fe5-adfc-d5f50a52aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 24) Next steps / further experiments (printed for convenience)\n",
    "print('\\nNext steps you can run:')\n",
    "print('- Run a full fine-tuning baseline (non-quantized) to compare accuracy and memory (requires GPU memory)')\n",
    "print('- Try different LoRA ranks (r) and lora_alpha to find a better accuracy/memory sweet spot')\n",
    "print('- Use smaller MAX_LENGTH or smaller batch size to fit in lower-memory GPUs')\n",
    "print('- Use HF Trainer callbacks or accelerate for distributed training')\n",
    "\n",
    "\n",
    "# End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b96bf9-6c1f-4a91-b984-040d602b3508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59356d-d3ab-4a0b-9487-986ba5821b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cfee2-d289-4e9b-a8cb-3557bc2a32d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
