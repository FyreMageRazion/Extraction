{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05187286-cfcd-4664-a50d-95e665ab11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pip install -U pip setuptools wheel\n",
    "pip install -U torch transformers datasets bitsandbytes accelerate peft[torch] evaluate sentencepiece wandb\n",
    "pip install huggingface_hub[hf_xet]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44d462-3bb5-493c-9053-725a22913211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# BERT QLoRA + LoRA fine-tuning on IMDB sentiment dataset (dipanjanS/imdb_sentiment_finetune_dataset20k)\n",
    "# Ready-to-run notebook-style script. Run cells sequentially in Jupyter / VSCode interactive.\n",
    "\n",
    "\n",
    "# %%\n",
    "# 1) Install required packages (uncomment if running in a fresh environment)\n",
    "# Note: If you already have these installed, you can skip this cell.\n",
    "\n",
    "\n",
    "# !pip install -q transformers==4.35.0 datasets bitsandbytes accelerate peft[torch] wandb evaluate sentencepiece\n",
    "\n",
    "\n",
    "# %%\n",
    "# 2) Imports and basic checks\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "AutoTokenizer,\n",
    "AutoModelForSequenceClassification,\n",
    "TrainingArguments,\n",
    "Trainer,\n",
    "DataCollatorWithPadding,\n",
    "BitsAndBytesConfig,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, get_peft_model_state_dict\n",
    "import evaluate\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22880af0-611c-4753-a37b-1cd06df6d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "print('Torch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device count:', torch.cuda.device_count())\n",
    "    print('Current device:', torch.cuda.current_device())\n",
    "    print('Device name:', torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576d0c2-102d-46e6-8c9f-231582642362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 3) Configs (edit these if you want)\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "DATASET = \"dipanjanS/imdb_sentiment_finetune_dataset20k\"\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-4\n",
    "OUTPUT_DIR = \"./bert_qlora_imdb_output\"\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# %%\n",
    "# 4) Load dataset\n",
    "raw_ds = load_dataset(DATASET)\n",
    "print(raw_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c28491-737c-45b3-a9fb-2b449642ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset should have a train split; if not, adapt accordingly.\n",
    "# We'll combine and then split to have a clean train/test split (80/20)\n",
    "if 'train' in raw_ds and len(raw_ds) == 1:\n",
    "    ds = raw_ds['train']\n",
    "else:\n",
    "    # if dataset already has train/test, we'll concatenate whatever splits exist\n",
    "    from datasets import concatenate_datasets\n",
    "    allsplits = [raw_ds[s] for s in raw_ds]\n",
    "    ds = concatenate_datasets(allsplits)\n",
    "\n",
    "\n",
    "print('Total examples:', len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcc660-9247-4a10-a3eb-26386f96cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 5) Train/test split\n",
    "split = ds.train_test_split(test_size=0.2, seed=SEED)\n",
    "train_ds = split['train']\n",
    "test_ds = split['test']\n",
    "print('Train size:', len(train_ds), 'Test size:', len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76309cea-1343-4ca1-926b-d0eed9961b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 6) Tokenizer and preprocessing\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "\n",
    "# ensure tokenizer has a padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "    examples['review'],\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "\n",
    "train_tok = train_ds.map(preprocess_function, batched=True, remove_columns=[c for c in train_ds.column_names if c != 'sentiment' and c != 'review'])\n",
    "test_tok = test_ds.map(preprocess_function, batched=True, remove_columns=[c for c in test_ds.column_names if c != 'sentiment' and c != 'review'])\n",
    "\n",
    "\n",
    "# Rename label column\n",
    "train_tok = train_tok.rename_column('sentiment', 'labels')\n",
    "test_tok = test_tok.rename_column('sentiment', 'labels')\n",
    "\n",
    "\n",
    "# Set format to PyTorch\n",
    "train_tok.set_format(type='torch', columns=[c for c in train_tok.column_names if c != 'review'])\n",
    "test_tok.set_format(type='torch', columns=[c for c in test_tok.column_names if c != 'review'])\n",
    "\n",
    "\n",
    "print(train_tok[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387f769-3f57-4ff9-b366-8534b68a8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 7) Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# %%\n",
    "# 8) Prepare quantization config (BitsAndBytes) for 4-bit QLoRA\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b3d6b-13a6-43d9-a43c-8db272834140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 9) Load the model in 4-bit mode and prepare for k-bit training\n",
    "print('\\nLoading model in 4-bit mode (this may take a while)...')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Important: for some older HF versions use load_in_4bit=True directly (kept as quantization_config for clarity)\n",
    "\n",
    "\n",
    "# resize token embeddings if tokenizer changed\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca992871-1d30-46bd-926e-5c8e08780529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 10) Prepare model for k-bit training (patching some layers for stability)\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "# %%\n",
    "# 11) LoRA config & applying PEFT\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"key\", \"value\"], # BERT attention modules\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a90e0a-bd28-491a-983c-b090c125024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2914d-68de-4ca1-90a4-d6cc5b336272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 12) Utility to count parameters\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "print('Total params:', total_params)\n",
    "print('Trainable params (after LoRA):', trainable_params)\n",
    "print('Trainable fraction: {:.6f}'.format(trainable_params/total_params))\n",
    "\n",
    "\n",
    "# Save the numbers to disk for reporting later\n",
    "with open(os.path.join(OUTPUT_DIR, 'param_counts.txt'), 'w') as f:\n",
    "    f.write(f\"total={total_params}\\ntrainable={trainable_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816a4b8-16f5-48d8-a367-6faa4ace6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 13) Metrics and compute_metrics function\n",
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = accuracy.compute(predictions=preds, references=labels)\n",
    "    p = precision.compute(predictions=preds, references=labels, average='binary')\n",
    "    r = recall.compute(predictions=preds, references=labels, average='binary')\n",
    "    f_1 = f1.compute(predictions=preds, references=labels, average='binary')\n",
    "    return {'accuracy': acc['accuracy'], 'precision': p['precision'], 'recall': r['recall'], 'f1': f_1['f1']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841f535-ac4e-44f9-8573-410aa0148670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 14) Training arguments and Trainer setup\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=OUTPUT_DIR,\n",
    "#     num_train_epochs=EPOCHS,\n",
    "#     per_device_train_batch_size=BATCH_SIZE,\n",
    "#     per_device_eval_batch_size=BATCH_SIZE,\n",
    "#     evaluation_strategy=\"epoch\",   # <-- run eval every epoch\n",
    "#     save_strategy=\"epoch\",\n",
    "#     logging_strategy='steps',\n",
    "#     logging_steps=50,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "#     weight_decay=0.01,\n",
    "#     fp16=True,\n",
    "#     gradient_accumulation_steps=1,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model='accuracy',\n",
    "#     greater_is_better=True,\n",
    "#     report_to=[\"wandb\"], # requires W&B login in the environment; remove if not using W&B\n",
    "#     )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=50,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model='accuracy'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43673b-dcfb-4da3-9756-42de4c92ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 15) (Optional) Initialize Weights & Biases if you want to log there; otherwise HF Trainer will still log locally\n",
    "# import wandb\n",
    "# wandb.init(project='bert-qlora-imdb', name='bert-qlora-run')\n",
    "\n",
    "\n",
    "# %%\n",
    "# 16) Report baseline GPU memory BEFORE training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    before_mem = torch.cuda.memory_allocated()\n",
    "    print('GPU memory allocated before training (bytes):', before_mem)\n",
    "else:\n",
    "    print('No CUDA device; memory measurements will be skipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49cb6dc-e1a5-4b4f-9a2d-27682e70eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 17) Train\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "end = time.time()\n",
    "print('Training time (s):', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae67d3-8778-43d8-a2a0-4a9e6d0cde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 18) GPU memory AFTER training\n",
    "if torch.cuda.is_available():\n",
    "    after_mem = torch.cuda.memory_allocated()\n",
    "    print('GPU memory allocated after training (bytes):', after_mem)\n",
    "    print('Delta (bytes):', after_mem - before_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacb081-09d2-4a56-a33b-76e65a2d01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 19) Save PEFT/LoRA adapters and model\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR, 'qlora_lora_model'))\n",
    "# Save the PEFT adapter separately\n",
    "model.save_pretrained(os.path.join(OUTPUT_DIR, 'qlora_lora_adapter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60c1dc-58a8-4097-ae00-b27a2dfee385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 20) Evaluate on the test set\n",
    "metrics = trainer.evaluate(eval_dataset=test_tok)\n",
    "print('Eval metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332f88e-5a6c-4dd2-88d1-edc4e784f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 21) Demonstrate trainable parameter counts before and after applying LoRA\n",
    "# NOTE: If you want to see the model parameter counts BEFORE adding LoRA, you would need to load the same model\n",
    "# without applying get_peft_model. For convenience we show how to do it (commented) and show counts for current model.\n",
    "\n",
    "\n",
    "# Uncomment to compute counts for a non-PEFT baseline (may be heavy if loaded in full precision):\n",
    "# baseline_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "# baseline_total, baseline_trainable = sum(p.numel() for p in baseline_model.parameters()), sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n",
    "# print('Baseline total params:', baseline_total, 'Baseline trainable:', baseline_trainable)\n",
    "\n",
    "\n",
    "print('Current total params:', total_params)\n",
    "print('Current trainable params (LoRA adapters):', trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab44970-61bd-4b9f-bedf-a1099a8863e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 22) Memory efficiency comparison between full fine-tuning and QLoRA\n",
    "# Provide guidance and a small programmatic check when possible. If you can load full model in the environment, uncomment.\n",
    "\n",
    "\n",
    "# NOTE: Full fine-tuning would require loading the full model in fp16 or fp32 and then fine-tuning which might not be possible on small GPUs.\n",
    "# The recommended approach: run the baseline on a machine with enough memory or use the HF Hub to retrieve known model sizes.\n",
    "\n",
    "\n",
    "# Example code to (optionally) measure full model memory usage (commented):\n",
    "# if torch.cuda.is_available():\n",
    "# torch.cuda.empty_cache()\n",
    "# t0 = torch.cuda.memory_allocated()\n",
    "# full = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to('cuda')\n",
    "# t1 = torch.cuda.memory_allocated()\n",
    "# print('Full model memory delta (bytes):', t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff90d1c-f7ae-4fa1-a727-1da7da975cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 23) Summary report generation (basic)\n",
    "summary = {\n",
    "'model_name': MODEL_NAME,\n",
    "'dataset': DATASET,\n",
    "'max_length': MAX_LENGTH,\n",
    "'batch_size': BATCH_SIZE,\n",
    "'epochs': EPOCHS,\n",
    "'learning_rate': LEARNING_RATE,\n",
    "'total_params': total_params,\n",
    "'trainable_params': trainable_params,\n",
    "'eval_metrics': metrics,\n",
    "}\n",
    "\n",
    "\n",
    "pprint(summary)\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'summary.txt'), 'w') as f:\n",
    "    f.write(str(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beca9f9-13ad-486b-857d-88817408b97a",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943889e-412a-4fe5-adfc-d5f50a52aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 24) Next steps / further experiments (printed for convenience)\n",
    "print('\\nNext steps you can run:')\n",
    "print('- Run a full fine-tuning baseline (non-quantized) to compare accuracy and memory (requires GPU memory)')\n",
    "print('- Try different LoRA ranks (r) and lora_alpha to find a better accuracy/memory sweet spot')\n",
    "print('- Use smaller MAX_LENGTH or smaller batch size to fit in lower-memory GPUs')\n",
    "print('- Use HF Trainer callbacks or accelerate for distributed training')\n",
    "\n",
    "\n",
    "# End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b96bf9-6c1f-4a91-b984-040d602b3508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59356d-d3ab-4a0b-9487-986ba5821b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cfee2-d289-4e9b-a8cb-3557bc2a32d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
